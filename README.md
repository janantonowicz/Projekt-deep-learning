# Klasyfikacja obrazÃ³w Fashion MNIST

### Projekt Python Web & Deep Learning

## Website demo


https://github.com/user-attachments/assets/006cd1d9-c479-4982-be2d-e6a27c273dc5



## Co realizujÄ… sieci?

Klasyfikacja obrazu i przypasowanie go do jednej z 10 kategorii:

`t-shirt`, `trouser`, `pullover`, `dress`, `coat`, `sandal`, `shirt`, `sneaker`, `bag`, `ankle boot`

## Opis datasetu

### Pochodzenie danych

Wykorzystano zbiÃ³r danych Fashion MNIST.

### Fashion MNIST

- 70,000 czarnobiaÅ‚ych obrazÃ³w przdstawiajÄ…cych ubrania z 10 kategorii
    
- Wymiary obrazu: **28 Ã— 28 pixels**

### Przetwarzanie wstÄ™pne:
    
- Dane wejÅ›ciowe zostaÅ‚y znormalizowane do zakresu **[0, 1]**
    
- KsztaÅ‚t obrazÃ³w zostaÅ‚ zmieniony na format 28x28x1 (dodanie kanaÅ‚u gÅ‚Ä™bi)
    

### PodziaÅ‚ na zbiory

|ZbiÃ³r|Liczba prÃ³bek|Procent [%]|
|---|---|---|
|Treningowy|48,000|68.5%|
|Walidacyjny|12,000|17%|
|Testowy|10,000|14.5%|

## Opis architektur sieci oraz procesu uczenia

### Bloki konwolucyjne

**Blok 1**

- Dwie warstwy Conv2D (32 filters, kernel 3Ã—3)
    
- MaxPooling2D
    

**Blok 2**

- Dwie warstwy Conv2D (64 filters, kernel 3Ã—3)
    
- MaxPooling2D
    

Warstwa konwolucyjna skanuje obraz poszukujÄ…c wzorcÃ³w. Pierwszy blok szuka 32 wzorcÃ³w (np. pionowe linie, kropki) Drugi blok szuka 64 bardziej zÅ‚oÅ¼onych wzorcÃ³w.
Kernel 3 x 3 to rozmiar okna skanujÄ…cego.

    

Po blokach konwolucyjnych zastosowano warstwÄ™ Flatten, ktÃ³ra przeksztaÅ‚ca mapy cech do postaci wektora, a nastÄ™pnie warstwy w peÅ‚ni poÅ‚Ä…czone (Dense).

python

```
X = tf.keras.layers.Flatten()(X)
X = tf.keras.layers.Dense(128, activation="relu")(X)
```

Warstwa ukryta skÅ‚ada siÄ™ z 128 neuronÃ³w z funkcjÄ… aktywacji ReLU, natomiast warstwa 
wyjÅ›ciowa posiada 10 neuronÃ³w z funkcjÄ… Softmax, odpowiadajÄ…cych liczbie klas w zbiorze danych.

### Funkcja Straty

Jako funkcjÄ™ straty wykorzystano Sparse Categorical Crossentropy, odpowiedniÄ… dla problemu wieloklasowej klasyfikacji z etykietami zapisanymi w postaci liczb caÅ‚kowitych.


### Optymalizator

python

```
optimizer = tf.keras.optimizers.Adam(1e-3)
```

Wykorzystano optymalizator Adam.

Algorytm decyduje jak zmieniÄ‡ wagi sieci neuronowej na podstawie obliczonej straty â€“ bÅ‚Ä™du, tak aby w nastÄ™pnym kroku wynik byÅ‚ lepszy.


### ğŸ”¹ Batch Size

```
BATCH_SIZE = 128
```

Model aktualizuje swoje wagi po przeanalizowaniu kaÅ¼dych z 128 obrazkÃ³w.

### Liczba epok i Early Stopping

Aby osiÄ…gnÄ…Ä‡ jak najlepszy wynik wykorzystaÅ‚em mechanizm **Early Stopping**. DziÄ™ki temu proces uczenia zostanie automatycznie przerwany jeÅ›li przez 10 kolejnych epok (`patience=10`) strata na zbiorze walidacyjnym nie ulegnie poprawie.
DziÄ™ki `restore_best_weights` finalny model to ten ktÃ³ry osiÄ…gnÄ…Å‚ najlepszy wynik, a nie ten z ostatniej epoki.
    

## Model z AugmentacjÄ…

- Losowe odbicie obrazu (RandomFlip)
- Losowe przesuniÄ™cie, obrÃ³t, przybliÅ¼enie oraz zmiana kontrastu
DziÄ™ki temu zwiÄ™kszamy rÃ³Å¼norodnoÅ›Ä‡ danych treningowych i zapobiegamy overfittingowi. WystÄ™puje mniejsza szansa Å¼e model nauczy siÄ™ zbioru testowego â€na pamiÄ™Ä‡â€

## PorÃ³wnanie modeli

Model z AugmentacjÄ… potrzebowaÅ‚ znacznie wiÄ™cej epok przy szkoleniu. DziÄ™ki temu radzi sobie lepiej od prostego modelu. Oba modele jednak majÄ… ograniczenia. PoniewaÅ¼ sÄ… nauczone na prostym zbiorze fashion MNIST osiÄ…gnÄ… znacznie gorsze wyniki przy spotkaniu z obrazami w innym formacie (np. przy obrazach o wiÄ™kszej rozdzielczoÅ›ci). Jako Å¼e jest to prosty model, przyjmuje tylko rozdzielczoÅ›Ä‡ 28x28 pikseli, zdjÄ™cie wrzucone w wiÄ™kszej rozdzielczoÅ›ci zostaje â€Å›ciÅ›niÄ™teâ€ do wymaganych wymiarÃ³w przez co moÅ¼e straciÄ‡ poczÄ…tkowe cechy charakterystyczne. 

### Augmented Model

<img width="945" height="357" alt="image" src="https://github.com/user-attachments/assets/257d1165-df07-477e-80c6-9dc8b6315507" />


```
313/313 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 5ms/step - accuracy: 0.9054 - loss: 0.2717
Test accuracy: 0.9064
```

### Simple Model

<img width="945" height="354" alt="image" src="https://github.com/user-attachments/assets/9fb6dc12-c0e9-40ff-95cd-fc2fb61968c8" />


```
313/313 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 6ms/step - accuracy: 0.9231 - loss: 0.2275
Test accuracy: 0.9226
```

### Wyniki

- **Prosty model osiÄ…gnÄ…Å‚ ~1.5% wyÅ¼szy test accuracy**.
    
- W obu modelach wystÄ™puje **overfitting**, pomimo funkcji early stopping, ktÃ³ra pomogÅ‚a ograniczyÄ‡ zjawisko.
    
- Model z AugmentacjÄ… byÅ‚ szkolony na znacznie wiÄ™kszej iloÅ›ci epok.
    
- Oba modele napotykajÄ… problemy przy obrazach innych niÅ¼ te ze zbioru treningowego (m.in., inny kolor tÅ‚a lub rozdzielczoÅ›Ä‡).
    

## Podsumowanie

Zgodnie z Testem to model prosty osiÄ…gnÄ…Å‚ lepszy wynik o 1,5% jednak w obu modelach wystÄ™puje overfitting â€“ dziÄ™ki zastosowaniu funkcji early stop udaÅ‚o siÄ™ zminimalizowaÄ‡ zjawisko (nadal jednak wystÄ™puje). MoÅ¼na zauwaÅ¼yÄ‡ znacznie gorsze wyniki przy obrazach z tÅ‚em w innym kolorze niÅ¼ ze zbioru treningowego
